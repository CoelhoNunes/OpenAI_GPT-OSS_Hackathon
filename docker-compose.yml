services:
  vllm:
    image: vllm/vllm-openai:latest
    environment:
      - HF_HOME=/models
    command: ["--model", "openai/gpt-oss-20b", "--host", "0.0.0.0", "--port", "8000", "--download-dir", "/models", "--max-model-len", "8192", "--trust-remote-code"]
    volumes:
      - vllm_models:/models
    shm_size: 2g
    ulimits:
      nofile:
        soft: 1048576
        hard: 1048576
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - "8003:8000"
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8000/v1/models"]
      interval: 15s
      timeout: 5s
      retries: 40
      start_period: 120s
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: leetcoach
      POSTGRES_USER: leetcoach
      POSTGRES_PASSWORD: leetcoach123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U leetcoach"]
      interval: 10s
      timeout: 5s
      retries: 5

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://leetcoach:leetcoach123@db:5432/leetcoach
      MODEL_ID: ${MODEL_ID:-openai/gpt-oss-20b}
      HF_ID: ${HF_ID:-openai/gpt-oss-20b}
      WEIGHTS_PATH: ${WEIGHTS_PATH:-}
      TORCH_DTYPE: ${TORCH_DTYPE:-bfloat16}
      MAX_TOKENS: ${MAX_TOKENS:-512}
      CONTEXT_LEN: ${CONTEXT_LEN:-8192}
      GPU_MEMORY_FRACTION: ${GPU_MEMORY_FRACTION:-0.9}
      BATCH_SIZE: ${BATCH_SIZE:-1}
      VLLM_BASE_URL: http://vllm:8000
      ALLOW_NON_GPT_OSS: false
      CUDA_ACCEL_URL: http://cuda_accel:8001
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      # cuda_accel:
      #   condition: service_healthy
      vllm:
        condition: service_healthy
    volumes:
      - ./api/src:/app/src
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  runner:
    build:
      context: ./runner
      dockerfile: Dockerfile
    environment:
      API_URL: http://api:8000
    ports:
      - "8002:8002"
    volumes:
      - ./runner:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  cuda_accel:
    build:
      context: ./cuda_accel
      dockerfile: Dockerfile
    environment:
      CUDA_VISIBLE_DEVICES: ${CUDA_VISIBLE_DEVICES:-0}
    ports:
      - "8001:8003"
    volumes:
      - ./cuda_accel:/app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
      NEXT_PUBLIC_WS_URL: ws://localhost:8000
    ports:
      - "3000:3000"
    depends_on:
      - api
    volumes:
      - ./web:/app
      - /app/node_modules

volumes:
  postgres_data:
  vllm_models:

networks:
  default:
    name: leetcoach-network
